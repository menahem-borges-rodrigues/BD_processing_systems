{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|               state|number_monitors|\n",
      "+--------------------+---------------+\n",
      "|          California|            170|\n",
      "|               Texas|            133|\n",
      "|           Minnesota|             94|\n",
      "|            Michigan|             92|\n",
      "|                Ohio|             91|\n",
      "|            New York|             67|\n",
      "|      South Carolina|             64|\n",
      "|             Montana|             62|\n",
      "|        Pennsylvania|             61|\n",
      "|             Florida|             55|\n",
      "|             Indiana|             52|\n",
      "|            Colorado|             51|\n",
      "|      North Carolina|             50|\n",
      "|            Illinois|             49|\n",
      "|          Washington|             43|\n",
      "|           Louisiana|             41|\n",
      "|             Arizona|             38|\n",
      "|              Kansas|             37|\n",
      "|             Georgia|             35|\n",
      "|            Kentucky|             34|\n",
      "|              Oregon|             32|\n",
      "|             Alabama|             31|\n",
      "|           Tennessee|             29|\n",
      "|           Wisconsin|             26|\n",
      "|          New Jersey|             24|\n",
      "|             Vermont|             23|\n",
      "|            Oklahoma|             22|\n",
      "|               Maine|             21|\n",
      "|         Mississippi|             21|\n",
      "|            Virginia|             19|\n",
      "|       Massachusetts|             19|\n",
      "|            Missouri|             18|\n",
      "|          New Mexico|             18|\n",
      "|   Country Of Mexico|             18|\n",
      "|                Iowa|             18|\n",
      "|               Idaho|             17|\n",
      "|       New Hampshire|             17|\n",
      "|            Maryland|             17|\n",
      "|         Connecticut|             15|\n",
      "|        Rhode Island|             13|\n",
      "|              Alaska|             12|\n",
      "|                Utah|             12|\n",
      "|            Arkansas|             11|\n",
      "|       West Virginia|             10|\n",
      "|             Wyoming|              9|\n",
      "|              Nevada|              9|\n",
      "|        South Dakota|              7|\n",
      "|        North Dakota|              7|\n",
      "|         Puerto Rico|              6|\n",
      "|            Nebraska|              6|\n",
      "|            Delaware|              6|\n",
      "|      Virgin Islands|              6|\n",
      "|              Hawaii|              5|\n",
      "|District Of Columbia|              5|\n",
      "+--------------------+---------------+\n",
      "\n",
      "process time, real time (0.3463723999999999, 14.947644399944693)\n"
     ]
    }
   ],
   "source": [
    "# Which states have more/less monitors? (Rank states!)\n",
    "# para responder é necesário contar todas as posições diferenciadas (lat long) para cada estado\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from time import process_time,perf_counter\n",
    "t_start,r_start=process_time(),perf_counter()\n",
    "spark = SparkSession.builder.master('local[*]').appName('words').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "try :\n",
    "    lines = sc.textFile('epa_hap_daily_summary-small.csv') #load txt\n",
    "    header=lines.first()\n",
    "    l2 = lines.filter( lambda line : line !=header) #filtra apenas linhas maiores que 0\n",
    "    l3 = l2.map( lambda line : line.split(',') ) # faz o split das linhas num array\n",
    "    logRows = l3.map( lambda arr : Row( state = arr[24], mon_pos = arr[5]+arr[6])) #map rdd com colonas nomeadas \n",
    "    DFsql = spark.createDataFrame( logRows ) # transforma rdd em dataframe\n",
    "    DFsql.createOrReplaceTempView(\"log\")\n",
    "    query_1 = spark.sql(\"SELECT state, size(collect_set(mon_pos)) AS number_monitors FROM log GROUP BY state ORDER BY number_monitors DESC\")\n",
    "    #query_1=spark.sql('SELECT state,DISTINCT COUNT(mon_pos) AS monitors FROM log GROUP BY state ORDER BY monitors DESC')\n",
    "    query_1.show(100)\n",
    "    t_stop,r_stop=process_time(),perf_counter()\n",
    "    print(f'process time, real time {t_stop-t_start,r_stop-r_start}')\n",
    "    sc.stop()\n",
    "except Exception as err:\n",
    "    print(err)\n",
    "    sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|          state_name|number_monitors|\n",
      "+--------------------+---------------+\n",
      "|          California|            170|\n",
      "|               Texas|            133|\n",
      "|           Minnesota|             94|\n",
      "|            Michigan|             92|\n",
      "|                Ohio|             91|\n",
      "|            New York|             67|\n",
      "|      South Carolina|             64|\n",
      "|             Montana|             62|\n",
      "|        Pennsylvania|             61|\n",
      "|             Florida|             55|\n",
      "|             Indiana|             52|\n",
      "|            Colorado|             51|\n",
      "|      North Carolina|             50|\n",
      "|            Illinois|             49|\n",
      "|          Washington|             43|\n",
      "|           Louisiana|             41|\n",
      "|             Arizona|             38|\n",
      "|              Kansas|             37|\n",
      "|             Georgia|             35|\n",
      "|            Kentucky|             34|\n",
      "|              Oregon|             32|\n",
      "|             Alabama|             31|\n",
      "|           Tennessee|             29|\n",
      "|           Wisconsin|             26|\n",
      "|          New Jersey|             24|\n",
      "|             Vermont|             23|\n",
      "|            Oklahoma|             22|\n",
      "|         Mississippi|             21|\n",
      "|               Maine|             21|\n",
      "|            Virginia|             19|\n",
      "|       Massachusetts|             19|\n",
      "|                Iowa|             18|\n",
      "|            Missouri|             18|\n",
      "|   Country Of Mexico|             18|\n",
      "|          New Mexico|             18|\n",
      "|            Maryland|             17|\n",
      "|       New Hampshire|             17|\n",
      "|               Idaho|             17|\n",
      "|         Connecticut|             15|\n",
      "|        Rhode Island|             13|\n",
      "|                Utah|             12|\n",
      "|              Alaska|             12|\n",
      "|            Arkansas|             11|\n",
      "|       West Virginia|             10|\n",
      "|             Wyoming|              9|\n",
      "|              Nevada|              9|\n",
      "|        North Dakota|              7|\n",
      "|        South Dakota|              7|\n",
      "|            Nebraska|              6|\n",
      "|      Virgin Islands|              6|\n",
      "|            Delaware|              6|\n",
      "|         Puerto Rico|              6|\n",
      "|              Hawaii|              5|\n",
      "|District Of Columbia|              5|\n",
      "+--------------------+---------------+\n",
      "\n",
      "process time, real time (0.07611349999999995, 7.895886200014502)\n"
     ]
    }
   ],
   "source": [
    "# Which states have more/less monitors? (Rank states!) com read.option na criação dataframe\n",
    "# para responder é necesário contar todas as posições diferenciadas (lat long) para cada estado\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from time import process_time,perf_counter\n",
    "t_start,r_start=process_time(),perf_counter()\n",
    "spark = SparkSession.builder.master('local[*]').appName('words').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "try :\n",
    "    main_data=spark.read.option('header','true').csv('epa_hap_daily_summary-small.csv')\n",
    "    main_data.createOrReplaceTempView(\"log\")\n",
    "    #query_1 = spark.sql(\"SELECT state, size(collect_set(mon_pos)) AS number_monitors FROM log GROUP BY state ORDER BY number_monitors DESC\")\n",
    "    query_1=spark.sql('SELECT state_name, COUNT(DISTINCT latitude,longitude) as number_monitors FROM log GROUP BY state_name ORDER BY number_monitors DESC')\n",
    "    query_1.show(100)\n",
    "    t_stop,r_stop=process_time(),perf_counter()\n",
    "    print(f'process time, real time {t_stop-t_start,r_stop-r_start}')\n",
    "    sc.stop()\n",
    "except Exception as err:\n",
    "    print(err)\n",
    "    sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|            counties|    media_poluicao|\n",
      "+--------------------+------------------+\n",
      "|              Tipton|            2556.0|\n",
      "|              Nassau|              19.0|\n",
      "|          Columbiana| 7.385690735785953|\n",
      "|     CHIHUAHUA STATE|         4.5121875|\n",
      "|            Caldwell| 4.116666666666667|\n",
      "|              Madera|            3.7393|\n",
      "|             Oakland| 2.888877848101266|\n",
      "|               Duval|2.7794603978494625|\n",
      "|              Kearny|2.3753333333333333|\n",
      "|               Bucks|2.3674999999999997|\n",
      "|     San Luis Obispo|2.3333333333333335|\n",
      "|           Edgecombe|             2.325|\n",
      "|              Pawnee|2.2941176470588234|\n",
      "|         Westchester|          2.239375|\n",
      "|            Johnston|             2.225|\n",
      "|            Hartford|2.0787055896226416|\n",
      "|           Granville|2.0285714285714285|\n",
      "|              Asotin|             2.025|\n",
      "|              Duplin|               2.0|\n",
      "|             Boulder| 1.960470901234568|\n",
      "|          Crittenden|1.9000000000000001|\n",
      "|              Yancey|               1.9|\n",
      "|         Los Angeles|1.8391350859879247|\n",
      "|           Iberville|1.8213132266666665|\n",
      "|             Caswell|           1.80075|\n",
      "|                Pitt|1.7999999999999998|\n",
      "|             Clinton|1.7583018867924527|\n",
      "|               Wayne|1.7137964212983239|\n",
      "|            Imperial|1.6478600515463917|\n",
      "|             Ozaukee|        1.55733332|\n",
      "|          Stillwater|1.5384615384615385|\n",
      "|           Crow Wing| 1.532046511627907|\n",
      "|                Boyd| 1.485702254901961|\n",
      "|          Gloucester|1.4814285714285715|\n",
      "|           Henderson|1.4295509090909093|\n",
      "|            Kennebec|             1.375|\n",
      "|          Stanislaus|1.2781941269841275|\n",
      "|           Muscatine|            1.2375|\n",
      "|          Deer Lodge|1.2135793388429752|\n",
      "|                Mesa|1.2109524924242425|\n",
      "|             Spokane|1.1469733510638298|\n",
      "|    East Baton Rouge|1.1444728456659612|\n",
      "|              Harris|1.1426282723128096|\n",
      "|               Davis|1.1418481240188378|\n",
      "|            Phillips|1.1414093959731544|\n",
      "|             Tuscola|     1.13696140625|\n",
      "|           Nez Perce|1.1226492795389047|\n",
      "|             Bayamon|1.1200363636363637|\n",
      "|           Pipestone|1.0807463414634146|\n",
      "|           Wyandotte|1.0779660104986872|\n",
      "|              Hudson|         1.0754546|\n",
      "|          Williamson|1.0616129032258064|\n",
      "|      St. Louis City|1.0544578440366965|\n",
      "|     Yellow Medicine|1.0511541666666666|\n",
      "|         San Joaquin|1.0142639721936149|\n",
      "|              Miller| 1.011219512195122|\n",
      "|               Ector|1.0014370984405456|\n",
      "|             Sherman|0.9735323943661971|\n",
      "|         St. Charles|0.9709866896551724|\n",
      "|          Otter Tail|0.9641929203539823|\n",
      "|                Kern|0.9552840147731252|\n",
      "|             El Paso|0.9325039253789317|\n",
      "|               Cloud|0.9306044444444446|\n",
      "|          Palm Beach|0.9141428571428573|\n",
      "|              DeKalb|0.9125199496626882|\n",
      "|              Itasca|0.8895128205128204|\n",
      "|                Lake|0.8883477899216881|\n",
      "|            Nicollet| 0.881576923076923|\n",
      "|           Fairfield|0.8765945608108108|\n",
      "|             Hampden|0.8682349224043717|\n",
      "|               Kings|0.8551156355455565|\n",
      "|              Fresno|0.8499170323179771|\n",
      "|           Sherburne|0.8408257575757577|\n",
      "|           Milwaukee|0.8367436675461741|\n",
      "|             Hampton|0.8288424908424908|\n",
      "|           Multnomah|0.8102990317052269|\n",
      "|             Tolland|0.8060031923076922|\n",
      "|                Park|0.8035137527114968|\n",
      "|             Cowlitz| 0.802640243902439|\n",
      "|BAJA CALIFORNIA N...|0.8018910386965376|\n",
      "|               Caddo|             0.798|\n",
      "|             Bristol|0.7900226190476192|\n",
      "|            Rockdale|0.7900198421052631|\n",
      "|            Sedgwick|0.7691381596587447|\n",
      "|             Allegan|0.7629881891891892|\n",
      "|           Merrimack|0.7562957446808511|\n",
      "|              Lehigh|0.7544444444444444|\n",
      "|              Wright|0.7452957746478873|\n",
      "|           Riverside| 0.741725700934578|\n",
      "|            Caroline|0.7399637916666667|\n",
      "|           Kalamazoo|0.7357420124223601|\n",
      "|             Greeley|0.7271684210526316|\n",
      "|              Denver|0.7212535775510206|\n",
      "|              Camden|0.7198732414075286|\n",
      "|                Cook|0.7069328430469428|\n",
      "|           Caledonia|0.7054105882352942|\n",
      "|            Morrison|0.7011904761904763|\n",
      "|              Ottawa|0.6909859050445101|\n",
      "|         Barceloneta| 0.687767955801105|\n",
      "|            Trumbull| 0.660764705882353|\n",
      "+--------------------+------------------+\n",
      "only showing top 100 rows\n",
      "\n",
      "process time, real time (0.1742410000000003, 12.430283399997279)\n"
     ]
    }
   ],
   "source": [
    "#Which counties have the best/worst air quality? (Rank counties considering pollutants’level\n",
    "#linha indice 16 media de valores por dia soma(media diarias)/numero de dias \n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from time import process_time,perf_counter\n",
    "t_start,r_start=process_time(),perf_counter()\n",
    "spark = SparkSession.builder.master('local[*]').appName('words').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "try :\n",
    "    lines = sc.textFile('epa_hap_daily_summary-small.csv') #load txt\n",
    "    header=lines.first()\n",
    "    l2 = lines.filter( lambda line : line !=header) #filtra apenas linhas maiores que 0\n",
    "    l3 = l2.map( lambda line : line.split(',') ) # faz o split das linhas num array\n",
    "    logRows = l3.map( lambda arr : Row( counties = arr[25], media_pol = arr[16])) #map rdd com colunas nomeadas\n",
    "    DFsql = spark.createDataFrame( logRows ) # transforma rdd em dataframe\n",
    "    DFsql.createOrReplaceTempView(\"log\")\n",
    "    query_2=spark.sql('SELECT counties, AVG(media_pol) AS media_poluicao FROM log GROUP BY counties ORDER BY media_poluicao DESC')\n",
    "    query_2.show(100)\n",
    "    t_stop,r_stop=process_time(),perf_counter()\n",
    "    print(f'process time, real time {t_stop-t_start,r_stop-r_start}')\n",
    "    sc.stop()\n",
    "except Exception as err:\n",
    "    print(err)\n",
    "    sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+\n",
      "| ano|              states|               media|\n",
      "+----+--------------------+--------------------+\n",
      "|1990|            Oklahoma|                 0.0|\n",
      "|1990|           Wisconsin|                 0.0|\n",
      "|1990|      Virgin Islands|                 0.0|\n",
      "|1990|       West Virginia|                 0.0|\n",
      "|1990|              Hawaii|1.970370370370370...|\n",
      "|1990|              Nevada|4.208000000000000...|\n",
      "|1990|              Alaska|4.420833333333333...|\n",
      "|1990|        South Dakota|            5.705E-4|\n",
      "|1990|          Washington|5.974999999999999E-4|\n",
      "|1990|             Wyoming|6.045454545454545E-4|\n",
      "|1990|                Utah|7.970588235294118E-4|\n",
      "|1990|          New Mexico|8.222222222222222E-4|\n",
      "|1990|              Oregon|8.596296296296297E-4|\n",
      "|1990|             Arizona|8.620134228187919E-4|\n",
      "|1990|               Maine|9.789285714285713E-4|\n",
      "|1990|            Colorado|0.002162374100719...|\n",
      "|1990|         Mississippi|0.002666666666666...|\n",
      "|1990|            Missouri|              0.0056|\n",
      "|1990|            Michigan|0.006559896373056996|\n",
      "|1990|         Connecticut|              0.0081|\n",
      "|1990|             Georgia|0.008366666666666666|\n",
      "|1990|         Puerto Rico|             0.01005|\n",
      "|1990|      North Carolina|              0.0143|\n",
      "|1990|             Alabama|            0.024325|\n",
      "|1990|                Iowa|              0.0332|\n",
      "|1990|        Pennsylvania|           0.1059625|\n",
      "|1990|                Ohio|            0.135716|\n",
      "|1990|            Illinois| 0.14575701219512197|\n",
      "|1990|          New Jersey|  0.2933352941176471|\n",
      "|1990|           Minnesota|            0.306488|\n",
      "|1990|          California| 0.41153099836333895|\n",
      "|1990|      South Carolina|  0.5598140350877193|\n",
      "|1990|District Of Columbia|  0.8261508196721312|\n",
      "|1990|            Virginia|  0.8451416666666666|\n",
      "|1990|           Louisiana|  0.9145945945945947|\n",
      "|1990|              Kansas|  1.1408154574132492|\n",
      "|1990|             Florida|  1.2765626315789476|\n",
      "|1990|            New York|   1.362972027972028|\n",
      "|1990|               Texas|  1.4824716546762589|\n",
      "|1990|             Montana|  2.0686790073529413|\n",
      "|1990|       Massachusetts|  3.0246823529411766|\n",
      "|1990|             Indiana|   4.098978378378379|\n",
      "|1990|           Tennessee|  170.40093066666665|\n",
      "|1991|            Arkansas|                 0.0|\n",
      "|1991|                Ohio|                 0.0|\n",
      "|1991|              Alaska|1.760000000000000...|\n",
      "|1991|        South Dakota|2.883333333333333E-4|\n",
      "|1991|             Wyoming|            3.258E-4|\n",
      "|1991|                Utah|3.378048780487805...|\n",
      "|1991|          New Mexico|3.986666666666666...|\n",
      "|1991|              Oregon|4.138095238095238E-4|\n",
      "|1991|              Nevada|4.826315789473683...|\n",
      "|1991|       West Virginia|5.466666666666667E-4|\n",
      "|1991|              Hawaii| 6.80754716981132E-4|\n",
      "|1991|          Washington|           7.1375E-4|\n",
      "|1991|             Georgia|           8.3875E-4|\n",
      "|1991|            Kentucky|8.585714285714285E-4|\n",
      "|1991|             Arizona|8.828402366863905E-4|\n",
      "|1991|      Virgin Islands|9.576470588235293E-4|\n",
      "|1991|               Maine|0.001306521739130...|\n",
      "|1991|             Vermont|0.001559090909090909|\n",
      "|1991|            Colorado| 0.00240126213592233|\n",
      "|1991|            Illinois|0.045304637681159415|\n",
      "|1991|           Wisconsin|             0.11625|\n",
      "|1991|           Minnesota| 0.15858126373626374|\n",
      "|1991|             Florida| 0.19555000000000003|\n",
      "|1991|        Pennsylvania| 0.21666666666666667|\n",
      "|1991|            Virginia|         0.236509875|\n",
      "|1991|           Tennessee|  0.2561980769230769|\n",
      "|1991|               Texas|   0.280053185840708|\n",
      "|1991|            Michigan|  0.3136863049853373|\n",
      "|1991|            Maryland| 0.31901639344262295|\n",
      "|1991|          California|  0.6735362628865981|\n",
      "|1991|District Of Columbia|  0.6772853968253968|\n",
      "|1991|             Montana|  0.7670011501597445|\n",
      "|1991|      South Carolina|  0.7982056737588653|\n",
      "|1991|            New York|  0.8852830188679243|\n",
      "|1991|              Kansas|  0.9181956521739129|\n",
      "|1991|          New Jersey|  1.0485551612903226|\n",
      "|1991|           Louisiana|  1.2000000000000002|\n",
      "|1991|             Indiana|  1.6614237288135594|\n",
      "|1992|                Ohio|                 0.0|\n",
      "|1992|              Alaska|1.026923076923077E-4|\n",
      "|1992|              Hawaii|1.894736842105263...|\n",
      "|1992|               Idaho|2.343478260869565E-4|\n",
      "|1992|          Washington|            2.696E-4|\n",
      "|1992|                Utah|2.836538461538461...|\n",
      "|1992|          New Mexico|3.153571428571428...|\n",
      "|1992|              Nevada|3.333333333333333E-4|\n",
      "|1992|             Wyoming|4.655813953488372E-4|\n",
      "|1992|            Arkansas|4.702272727272727E-4|\n",
      "|1992|             Vermont|4.969565217391304E-4|\n",
      "|1992|        South Dakota|4.973913043478262E-4|\n",
      "|1992|             Arizona|5.238461538461539E-4|\n",
      "|1992|            Virginia|5.474074074074074E-4|\n",
      "|1992|               Maine| 6.71111111111111E-4|\n",
      "|1992|             Georgia|8.029166666666666E-4|\n",
      "|1992|       West Virginia|8.235135135135136E-4|\n",
      "|1992|              Oregon|9.852380952380952E-4|\n",
      "|1992|            Kentucky|0.001314090909090909|\n",
      "+----+--------------------+--------------------+\n",
      "only showing top 100 rows\n",
      "\n",
      "process time, real time (0.15359439999999935, 11.243075200123712)\n"
     ]
    }
   ],
   "source": [
    "#Q.3) Which states have the best/worst air quality in each year? (Rank states per year considering pollutants’ level!\n",
    "# linha 12 contem data\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from time import process_time,perf_counter\n",
    "t_start,r_start=process_time(),perf_counter()\n",
    "spark = SparkSession.builder.master('local[*]').appName('words').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "try :\n",
    "    lines = sc.textFile('epa_hap_daily_summary-small.csv') #load txt\n",
    "    header=lines.first()\n",
    "    l2 = lines.filter( lambda line : line !=header) #filtra apenas linhas maiores que 0\n",
    "    l3 = l2.map( lambda line : line.split(',') ) # faz o split das linhas num array\n",
    "    logRows = l3.map( lambda arr : Row( states = arr[24],data=arr[11], media_pol = arr[16])) #map rdd com colonas nomeadas \n",
    "    DFsql = spark.createDataFrame( logRows ) # transforma rdd em dataframe\n",
    "    DFsql.createOrReplaceTempView(\"log\")\n",
    "    query_3=spark.sql('SELECT SUBSTRING(data,0,4) AS ano, states, AVG(media_pol) AS media FROM log GROUP BY ano,states ORDER BY ano,media') \n",
    "    query_3.show(100)\n",
    "    t_stop,r_stop=process_time(),perf_counter()\n",
    "    print(f'process time, real time {t_stop-t_start,r_stop-r_start}')    \n",
    "    sc.stop()\n",
    "except Exception as err:\n",
    "    print(err)\n",
    "    sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process time, real time (0.24987970000000104, 1.7246517001185566)\n",
      "+--------------------+------------------+\n",
      "|          state_name|              dist|\n",
      "+--------------------+------------------+\n",
      "|            Virginia| 715.4329730260437|\n",
      "|              Alaska| 603.6996422410685|\n",
      "|               Texas|  512.183989163014|\n",
      "|             Vermont|504.06323548508084|\n",
      "|            Illinois|440.85401432128594|\n",
      "|        South Dakota|365.84513743232617|\n",
      "|             Florida| 336.5449146570832|\n",
      "|          California|328.22638131553657|\n",
      "|            Michigan| 326.4116064851129|\n",
      "|              Nevada|326.28118071973904|\n",
      "|            Nebraska| 307.1411826055287|\n",
      "|              Kansas| 292.0796841296708|\n",
      "|               Idaho|289.63507327563104|\n",
      "|             Montana| 286.8383352756942|\n",
      "|            New York| 283.7273398637172|\n",
      "|             Wyoming| 283.6405863374747|\n",
      "|              Oregon| 268.8538079232644|\n",
      "|        Pennsylvania|251.41517634057166|\n",
      "|        North Dakota|  248.421930732627|\n",
      "|            Oklahoma|236.88257437298168|\n",
      "|           Tennessee|235.97614951487606|\n",
      "|            Missouri|234.32953412794035|\n",
      "|          Washington|219.98044806799825|\n",
      "|            Kentucky|219.95151680752107|\n",
      "|                Iowa| 206.5989410368908|\n",
      "|           Wisconsin| 202.8469300797848|\n",
      "|           Minnesota|  195.068270828248|\n",
      "|                Utah| 184.9134304071158|\n",
      "|             Georgia|184.34823507347102|\n",
      "|          New Mexico|183.18912128523763|\n",
      "|            Colorado|180.25974203315081|\n",
      "|      North Carolina|179.09404815356976|\n",
      "|             Arizona|178.87574055612177|\n",
      "|             Indiana| 177.7419577718975|\n",
      "|                Ohio|176.18296482931538|\n",
      "|         Mississippi| 174.2386099835142|\n",
      "|           Louisiana|173.27631230948307|\n",
      "|               Maine| 167.7714354141443|\n",
      "|             Alabama|167.57779614651392|\n",
      "|            Arkansas|157.85010472330006|\n",
      "|              Hawaii|155.73279515048372|\n",
      "|       West Virginia| 144.4936388149375|\n",
      "|      South Carolina|131.49188669764894|\n",
      "|       New Hampshire|115.62205092346309|\n",
      "|       Massachusetts| 92.35401256790219|\n",
      "|            Maryland| 89.28759445559282|\n",
      "|          New Jersey| 80.74367303780123|\n",
      "|      Virgin Islands| 73.45806087692814|\n",
      "|            Delaware| 51.57977048023351|\n",
      "|         Connecticut|  49.9897454877856|\n",
      "|         Puerto Rico| 32.73151627576544|\n",
      "|        Rhode Island|22.192520606570362|\n",
      "|District Of Columbia| 11.75712604636944|\n",
      "|   Country Of Mexico|              null|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Q.4) For each state, what is the average distance (in km) of the monitors in that state to the state center? \n",
    "#For simplicity, assume that 1 degree of latitude or logitude equals to 111 km. (Monitor dispersion per state!)\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import math\n",
    "from time import process_time,perf_counter\n",
    "t_start,r_start=process_time(),perf_counter()\n",
    "spark = SparkSession.builder.master('local[*]').appName('words').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "try :\n",
    "    #load data\n",
    "    main_data=spark.read.option('header','true').csv('epa_hap_daily_summary-small.csv')#.select(col('state_name'),col('latitude'),col('longitude')).distinct() #data principal\n",
    "    aux_data=spark.read.option('header','true').csv('usa_states.csv')#.select(col('Name'), col('MinLat'),col('MaxLat'),col('MinLon'),col('MaxLon')) #data auxiliar\n",
    "    #create tempviews SQL\n",
    "    main_data.createOrReplaceTempView('maindata')\n",
    "    aux_data.createOrReplaceTempView('auxdata')\n",
    "    #start sql processing \n",
    "    monitors=spark.sql('SELECT DISTINCT state_name,latitude,longitude FROM maindata') #get distinct monitors\n",
    "    state_center=spark.sql('SELECT Name,(MinLat+MaxLat)/2 AS lat_center,(MinLon+MaxLon)/2 AS lon_center FROM auxdata') #get state center\n",
    "    # create new tempviews\n",
    "    monitors.createOrReplaceTempView('monitors')\n",
    "    state_center.createOrReplaceTempView('state_center')\n",
    "    #join tables\n",
    "    joint_data=spark.sql('SELECT monitors.state_name,monitors.latitude,monitors.longitude, state_center.lat_center,state_center.lon_center FROM monitors LEFT JOIN state_center ON monitors.state_name=state_center.Name')\n",
    "    joint_data.createOrReplaceTempView('full_data')\n",
    "    query=spark.sql('SELECT state_name,AVG(SQRT(POWER((latitude-lat_center)*111,2)+POWER((longitude-lon_center)*111,2))) AS dist FROM full_data GROUP BY state_name ORDER BY dist DESC')\n",
    "    t_stop,r_stop=process_time(),perf_counter()\n",
    "    print(f'process time, real time {t_stop-t_start,r_stop-r_start}')\n",
    "    query.show(500)\n",
    "    sc.stop()\n",
    "except Exception as err:\n",
    "    print(err)\n",
    "    sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process time, real time (0.09448460000000125, 1.6038611999247223)\n",
      "+--------------------+---+---+---+---+\n",
      "|          state_name| NE| SE| SW| MW|\n",
      "+--------------------+---+---+---+---+\n",
      "|                Utah|  0|  3|  3|  6|\n",
      "|              Hawaii|  2|  1|  0|  2|\n",
      "|   Country Of Mexico|  0|  0|  0|  0|\n",
      "|           Minnesota| 11| 50| 21| 12|\n",
      "|                Ohio| 30| 10| 36| 15|\n",
      "|              Oregon|  3|  1| 13| 15|\n",
      "|            Arkansas|  2|  1|  5|  3|\n",
      "|District Of Columbia|  0|  1|  3|  1|\n",
      "|               Texas| 34| 72|  3| 24|\n",
      "|        North Dakota|  1|  1|  3|  2|\n",
      "|        Pennsylvania|  3| 36| 18|  4|\n",
      "|         Connecticut|  5|  0|  8|  2|\n",
      "|             Vermont|  1|  1|  5| 16|\n",
      "|            Nebraska|  1|  3|  0|  2|\n",
      "|              Nevada|  2|  5|  0|  2|\n",
      "|         Puerto Rico|  4|  0|  1|  1|\n",
      "|          Washington|  6|  2| 15| 20|\n",
      "|            Illinois| 32|  1| 14|  2|\n",
      "|            Oklahoma| 18|  2|  0|  2|\n",
      "|      Virgin Islands|  0|  0|  6|  0|\n",
      "|            Delaware|  0|  0|  2|  4|\n",
      "|              Alaska|  4|  2|  3|  3|\n",
      "|          New Mexico|  1|  2|  3| 12|\n",
      "|       West Virginia|  2|  0|  5|  3|\n",
      "|            Missouri|  9|  3|  2|  4|\n",
      "|        Rhode Island| 12|  0|  0|  1|\n",
      "|             Georgia|  4|  5|  5| 21|\n",
      "|             Montana| 11|  5| 36| 10|\n",
      "|            Michigan| 14| 74|  1|  3|\n",
      "|            Virginia|  8|  7|  4|  0|\n",
      "|      North Carolina| 26|  5|  0| 19|\n",
      "|             Wyoming|  2|  2|  2|  3|\n",
      "|              Kansas| 18|  9|  8|  2|\n",
      "|          New Jersey| 18|  1|  4|  1|\n",
      "|            Maryland| 16|  0|  0|  1|\n",
      "|             Alabama|  5|  5|  7| 14|\n",
      "|             Arizona|  2| 16| 10| 10|\n",
      "|                Iowa|  6|  8|  4|  0|\n",
      "|       Massachusetts| 11|  4|  0|  4|\n",
      "|            Kentucky| 13|  2| 16|  3|\n",
      "|           Louisiana|  0| 35|  1|  5|\n",
      "|         Mississippi|  4| 12|  5|  0|\n",
      "|           Tennessee|  8|  4|  8|  9|\n",
      "|       New Hampshire|  2| 11|  4|  0|\n",
      "|             Indiana| 18|  8|  8| 18|\n",
      "|             Florida| 27| 23|  0|  5|\n",
      "|               Idaho|  0|  3|  7|  7|\n",
      "|      South Carolina| 10| 18|  3| 33|\n",
      "|        South Dakota|  0|  4|  3|  0|\n",
      "|          California|  2| 68| 16| 84|\n",
      "|            New York|  5| 43|  3| 16|\n",
      "|           Wisconsin|  2| 21|  1|  2|\n",
      "|            Colorado| 25|  4|  5| 17|\n",
      "|               Maine|  2|  6| 12|  1|\n",
      "+--------------------+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Q.5) How many sensors there are per quadrant (NW, NE, SE, SW) in each state? To answer this question, you should approximate each state’s area to a rectangle as\n",
    "#defined in the file “usa_satates.csv”, and divide that area in 4 quadrants (NW,NE, SE, SW). (Count monitors per sate qudrant!\n",
    "\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import math\n",
    "from time import process_time,perf_counter\n",
    "t_start,r_start=process_time(),perf_counter()\n",
    "spark = SparkSession.builder.master('local[*]').appName('words').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "try :\n",
    "    #load data\n",
    "    main_data=spark.read.option('header','true').csv('epa_hap_daily_summary-small.csv')#.select(col('state_name'),col('latitude'),col('longitude')).distinct() #data principal\n",
    "    aux_data=spark.read.option('header','true').csv('usa_states.csv')#.select(col('Name'), col('MinLat'),col('MaxLat'),col('MinLon'),col('MaxLon')) #data auxiliar\n",
    "    #create tempviews SQL\n",
    "    main_data.createOrReplaceTempView('maindata')\n",
    "    aux_data.createOrReplaceTempView('auxdata')\n",
    "    #start sql processing \n",
    "    monitors=spark.sql('SELECT DISTINCT state_name,latitude,longitude FROM maindata') #get distinct monitors\n",
    "    state_center=spark.sql('SELECT Name,(MinLat+MaxLat)/2 AS lat_center,(MinLon+MaxLon)/2 AS lon_center FROM auxdata') #get state center\n",
    "    # create new tempviews\n",
    "    monitors.createOrReplaceTempView('monitors')\n",
    "    state_center.createOrReplaceTempView('state_center')\n",
    "    #join tables\n",
    "    joint_data=spark.sql('SELECT monitors.state_name,monitors.latitude,monitors.longitude, state_center.lat_center,state_center.lon_center FROM monitors LEFT JOIN state_center ON monitors.state_name=state_center.Name')\n",
    "    joint_data.createOrReplaceTempView('full_data')\n",
    "    organize=spark.sql('SELECT state_name,CASE WHEN latitude>lat_center and longitude>lon_center THEN 1 ELSE 0 END AS NE,CASE WHEN latitude<lat_center and longitude>lon_center THEN 1 ELSE 0 END AS SE,CASE WHEN latitude<lat_center and longitude<lon_center THEN 1 ELSE 0 END AS SW,CASE WHEN latitude>lat_center and longitude<lon_center THEN 1 ELSE 0 END AS NW FROM full_data')\n",
    "    organize.createOrReplaceTempView('mon_quad')\n",
    "    query=spark.sql('SELECT state_name,SUM(NE) AS NE,SUM(SE) AS SE,SUM(SW) AS SW,SUM(NW) AS MW FROM mon_quad GROUP BY state_name') \n",
    "    t_stop,r_stop=process_time(),perf_counter()\n",
    "    print(f'process time, real time {t_stop-t_start,r_stop-r_start}')   \n",
    "    query.show(500)\n",
    "    sc.stop()\n",
    "except Exception as err:\n",
    "    print(err)\n",
    "    sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
